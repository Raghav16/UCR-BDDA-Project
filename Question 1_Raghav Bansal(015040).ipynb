{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('CoronavirusNLP').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('Corona_NLP_train.csv', header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "|            UserName|  ScreenName|            Location|   TweetAt|       OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------------------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "|                3799|       48751|              London|16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         111|\n",
      "|                3800|       48752|                  UK|16-03-2020|advice Talk to yo...| Positive|         237|\n",
      "|                3801|       48753|           Vagabonds|16-03-2020|Coronavirus Austr...| Positive|         131|\n",
      "|                3802|       48754|                null|16-03-2020|My food stock is ...|     null|          51|\n",
      "|              PLEASE| don't panic| THERE WILL BE EN...|      null|                null|     null|        null|\n",
      "|           Stay calm|  stay safe.|                null|      null|                null|     null|        null|\n",
      "|#COVID19france #C...|    Positive|                null|      null|                null|     null|        null|\n",
      "+--------------------+------------+--------------------+----------+--------------------+---------+------------+\n",
      "only showing top 7 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, UserName: string, ScreenName: string, Location: string, TweetAt: string, OriginalTweet: string, Sentiment: string]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UserName', 'ScreenName', 'Location', 'TweetAt', 'OriginalTweet', 'Sentiment']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68046, 6)\n"
     ]
    }
   ],
   "source": [
    "print((data.count(),len(data.columns)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.withColumn('Tweet_length', length(data['OriginalTweet']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "|            UserName|          ScreenName|            Location|             TweetAt|       OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "|                3799|               48751|              London|          16-03-2020|@MeNyrbie @Phil_G...|  Neutral|         111|\n",
      "|                3800|               48752|                  UK|          16-03-2020|advice Talk to yo...| Positive|         237|\n",
      "|                3801|               48753|           Vagabonds|          16-03-2020|Coronavirus Austr...| Positive|         131|\n",
      "|                3802|               48754|                null|          16-03-2020|My food stock is ...|     null|          51|\n",
      "|              PLEASE|         don't panic| THERE WILL BE EN...|                null|                null|     null|        null|\n",
      "|           Stay calm|          stay safe.|                null|                null|                null|     null|        null|\n",
      "|#COVID19france #C...|            Positive|                null|                null|                null|     null|        null|\n",
      "|                3803|               48755|                null|          16-03-2020|Me, ready to go a...|     null|          60|\n",
      "|Not because I'm p...| but because my f...|          but please| don't panic. It ...|                null|     null|        null|\n",
      "|#CoronavirusFranc...|  Extremely Negative|                null|                null|                null|     null|        null|\n",
      "|                3804|               48756|ÜT: 36.319708,-82...|          16-03-2020|As news of the re...| Positive|         249|\n",
      "|                3805|               48757|35.926541,-78.753267|          16-03-2020|\"Cashier at groce...| Positive|         184|\n",
      "|                3806|               48758|             Austria|          16-03-2020|Was at the superm...|     null|          61|\n",
      "|#toiletpapercrisi...|             Neutral|                null|                null|                null|     null|        null|\n",
      "|                3807|               48759|     Atlanta, GA USA|          16-03-2020|Due to COVID-19 o...| Positive|         280|\n",
      "|                3808|               48760|    BHAVNAGAR,GUJRAT|          16-03-2020|For corona preven...| Negative|         267|\n",
      "|                3809|               48761|      Makati, Manila|          16-03-2020|All month there h...|  Neutral|         276|\n",
      "|                3810|               48762|Pitt Meadows, BC,...|          16-03-2020|Due to the Covid-...|     null|          79|\n",
      "|The wait time may...| particularly bee...|                null|                null|                null|     null|        null|\n",
      "|We thank you for ...|  Extremely Positive|                null|                null|                null|     null|        null|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments= ['Positive','Negative','Neutral','Extremely Positive','Extremely Negative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.filter(data.Sentiment.isin(sentiments))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|         Sentiment|\n",
      "+------------------+\n",
      "|Extremely Negative|\n",
      "|           Neutral|\n",
      "|          Positive|\n",
      "|          Negative|\n",
      "|Extremely Positive|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('Sentiment').distinct().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('Sentiment').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|         Sentiment|count|\n",
      "+------------------+-----+\n",
      "|Extremely Negative| 3751|\n",
      "|           Neutral| 5224|\n",
      "|          Positive| 7718|\n",
      "|          Negative| 6857|\n",
      "|Extremely Positive| 4412|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Sentiment').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|         Sentiment| avg(Tweet_length)|\n",
      "+------------------+------------------+\n",
      "|Extremely Negative| 209.6656891495601|\n",
      "|           Neutral| 151.2949846860643|\n",
      "|          Positive|193.66195905675045|\n",
      "|          Negative| 189.6651596908269|\n",
      "|Extremely Positive| 215.0605167724388|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Sentiment').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|            Location| avg(Tweet_length)|\n",
      "+--------------------+------------------+\n",
      "|                 ...|             197.0|\n",
      "| Mumbai, Maharashtra|154.66666666666666|\n",
      "| Brisbane, Australia|             207.0|\n",
      "|West Woofle-Dust ...|             157.0|\n",
      "|   St Petersburg, FL|169.57142857142858|\n",
      "| All across Michigan|             224.0|\n",
      "|     Northumberland |             280.0|\n",
      "|     stoke on trent |             187.0|\n",
      "|some where around...|             126.0|\n",
      "|           Bangalore|176.21052631578948|\n",
      "|           Norn Iron|             244.0|\n",
      "|Horsham, Pennsylv...|             189.0|\n",
      "|       Shimla  India|              89.0|\n",
      "|Ferrara, Emilia R...|             230.0|\n",
      "|      Luton, England|             198.0|\n",
      "|              Heaven|             198.0|\n",
      "|       St George, UT|             188.0|\n",
      "|Just to the left ...|             205.0|\n",
      "|           Worcester|             258.5|\n",
      "|      Nellore/Canada|             280.0|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Location').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            Location|count|\n",
      "+--------------------+-----+\n",
      "|                 ...|    1|\n",
      "| Mumbai, Maharashtra|    3|\n",
      "| Brisbane, Australia|    4|\n",
      "|West Woofle-Dust ...|    1|\n",
      "|   St Petersburg, FL|    7|\n",
      "| All across Michigan|    1|\n",
      "|     Northumberland |    1|\n",
      "|     stoke on trent |    1|\n",
      "|some where around...|    1|\n",
      "|           Bangalore|   19|\n",
      "|           Norn Iron|    1|\n",
      "|Horsham, Pennsylv...|    1|\n",
      "|       Shimla  India|    1|\n",
      "|Ferrara, Emilia R...|    1|\n",
      "|      Luton, England|    1|\n",
      "|              Heaven|    1|\n",
      "|       St George, UT|    1|\n",
      "|Just to the left ...|    1|\n",
      "|           Worcester|    2|\n",
      "|      Nellore/Canada|    1|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('Location').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|Tweet_length|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|         111|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|         237|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|         131|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|         249|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|         184|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|         280|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|         267|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|         276|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|         278|\n",
      "|    3813|     48765|                null|16-03-2020|ADARA Releases CO...|          Positive|         185|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|         184|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|         251|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|         255|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|         278|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|         202|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|         279|\n",
      "|    3829|     48781|                null|16-03-2020|There Is of in th...|          Negative|         114|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|         122|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|         225|\n",
      "|    3837|     48789|                null|16-03-2020|my wife works ret...|          Negative|         288|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27962, 7)\n"
     ]
    }
   ],
   "source": [
    "print((df.count(),len(df.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import isnan,when,count,col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|UserName|ScreenName|Location|TweetAt|OriginalTweet|Sentiment|Tweet_length|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "|       0|         0|    6152|      0|            0|        0|           0|\n",
      "+--------+----------+--------+-------+-------------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, RegexTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol = \"OriginalTweet\", outputCol = \"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol=\"token_text\", outputCol = \"stop_tokens\")\n",
    "#Cleaned version of Tokens\n",
    "#Counting Occurnace of tokens\n",
    "count_vec = CountVectorizer(inputCol = \"stop_tokens\", outputCol = \"c_vec\")\n",
    "idf = IDF(inputCol = \"c_vec\", outputCol = \"tf_idf\")\n",
    "\n",
    "Corona_to_num = StringIndexer(inputCol = \"Sentiment\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.linalg import Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up = VectorAssembler(inputCols =[\"tf_idf\", \"Tweet_length\"], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes, RandomForestClassifier, DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB= NaiveBayes()\n",
    "RF = RandomForestClassifier(numTrees = 50)\n",
    "DTC = DecisionTreeClassifier (maxDepth = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prep_pipeline = Pipeline(stages =[Corona_to_num,tokenizer, stopremove,count_vec,idf,clean_up])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = data_prep_pipeline.fit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = cleaner.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|UserName|ScreenName|            Location|   TweetAt|       OriginalTweet|         Sentiment|Tweet_length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|    3799|     48751|              London|16-03-2020|@MeNyrbie @Phil_G...|           Neutral|         111|  2.0|[@menyrbie, @phil...|[@menyrbie, @phil...|(78305,[14499,289...|(78305,[14499,289...|(78306,[14499,289...|\n",
      "|    3800|     48752|                  UK|16-03-2020|advice Talk to yo...|          Positive|         237|  0.0|[advice, talk, to...|[advice, talk, ne...|(78305,[13,14,133...|(78305,[13,14,133...|(78306,[13,14,133...|\n",
      "|    3801|     48753|           Vagabonds|16-03-2020|Coronavirus Austr...|          Positive|         131|  0.0|[coronavirus, aus...|[coronavirus, aus...|(78305,[8,14,37,7...|(78305,[8,14,37,7...|(78306,[8,14,37,7...|\n",
      "|    3804|     48756|ÜT: 36.319708,-82...|16-03-2020|As news of the re...|          Positive|         249|  0.0|[as, news, of, th...|[news, regions, ...|(78305,[7,8,31,47...|(78305,[7,8,31,47...|(78306,[7,8,31,47...|\n",
      "|    3805|     48757|35.926541,-78.753267|16-03-2020|\"Cashier at groce...|          Positive|         184|  0.0|[\"cashier, at, gr...|[\"cashier, grocer...|(78305,[3,6,18,60...|(78305,[3,6,18,60...|(78306,[3,6,18,60...|\n",
      "|    3807|     48759|     Atlanta, GA USA|16-03-2020|Due to COVID-19 o...|          Positive|         280|  0.0|[due, to, covid-1...|[due, covid-19, r...|(78305,[1,6,8,13,...|(78305,[1,6,8,13,...|(78306,[1,6,8,13,...|\n",
      "|    3808|     48760|    BHAVNAGAR,GUJRAT|16-03-2020|For corona preven...|          Negative|         267|  1.0|[for, corona, pre...|[corona, preventi...|(78305,[11,13,14,...|(78305,[11,13,14,...|(78306,[11,13,14,...|\n",
      "|    3809|     48761|      Makati, Manila|16-03-2020|All month there h...|           Neutral|         276|  2.0|[all, month, ther...|[month, crowding,...|(78305,[48,70,147...|(78305,[48,70,147...|(78306,[48,70,147...|\n",
      "|    3811|     48763|          Horningsea|16-03-2020|#horningsea is a ...|Extremely Positive|         278|  3.0|[#horningsea, is,...|[#horningsea, car...|(78305,[13,14,23,...|(78305,[13,14,23,...|(78306,[13,14,23,...|\n",
      "|    3813|     48765|                null|16-03-2020|ADARA Releases CO...|          Positive|         185|  0.0|[adara, releases,...|[adara, releases,...|(78305,[8,10,23,5...|(78305,[8,10,23,5...|(78306,[8,10,23,5...|\n",
      "|    3818|     48770|          Denver, CO|16-03-2020|For those who are...|          Positive|         184|  0.0|[for, those, who,...|[struggling,, ple...|(78305,[4,8,24,38...|(78305,[4,8,24,38...|(78306,[4,8,24,38...|\n",
      "|    3819|     48771|southampton soxx xxx|16-03-2020|with 100  nations...|Extremely Negative|         251|  4.0|[with, 100, , nat...|[100, , nations, ...|(78305,[1,4,9,11,...|(78305,[1,4,9,11,...|(78306,[1,4,9,11,...|\n",
      "|    3823|     48775|    Downstage centre|16-03-2020|@10DowningStreet ...|          Negative|         255|  1.0|[@10downingstreet...|[@10downingstreet...|(78305,[4,21,44,7...|(78305,[4,21,44,7...|(78306,[4,21,44,7...|\n",
      "|    3824|     48776|              London|16-03-2020|UK #consumer poll...|Extremely Positive|         278|  3.0|[uk, #consumer, p...|[uk, #consumer, p...|(78305,[10,37,54,...|(78305,[10,37,54,...|(78306,[10,37,54,...|\n",
      "|    3825|     48777|      Ketchum, Idaho|16-03-2020|In preparation fo...|          Negative|         202|  1.0|[in, preparation,...|[preparation, hig...|(78305,[4,8,24,33...|(78305,[4,8,24,33...|(78306,[4,8,24,33...|\n",
      "|    3826|     48778| Everywhere You Are!|16-03-2020|This morning I te...|Extremely Negative|         279|  4.0|[this, morning, i...|[morning, tested,...|(78305,[1,7,11,36...|(78305,[1,7,11,36...|(78306,[1,7,11,36...|\n",
      "|    3829|     48781|                null|16-03-2020|There Is of in th...|          Negative|         114|  1.0|[there, is, of, i...|[country, , empty...|(78305,[1,4,7,34,...|(78305,[1,4,7,34,...|(78306,[1,4,7,34,...|\n",
      "|    3834|     48786|             Sverige|16-03-2020|Went to the super...|           Neutral|         122|  2.0|[went, to, the, s...|[went, supermarke...|(78305,[5,47,48,6...|(78305,[5,47,48,6...|(78306,[5,47,48,6...|\n",
      "|    3836|     48788|              Canada|16-03-2020|Worried about the...|          Positive|         225|  0.0|[worried, about, ...|[worried, impact,...|(78305,[8,12,23,2...|(78305,[8,12,23,2...|(78306,[8,12,23,2...|\n",
      "|    3837|     48789|                null|16-03-2020|my wife works ret...|          Negative|         288|  1.0|[my, wife, works,...|[wife, works, ret...|(78305,[6,28,33,9...|(78305,[6,28,33,9...|(78306,[6,28,33,9...|\n",
      "+--------+----------+--------------------+----------+--------------------+------------------+------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_data.select(['label','features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|            features|\n",
      "+-----+--------------------+\n",
      "|  2.0|(78306,[14499,289...|\n",
      "|  0.0|(78306,[13,14,133...|\n",
      "|  0.0|(78306,[8,14,37,7...|\n",
      "|  0.0|(78306,[7,8,31,47...|\n",
      "|  0.0|(78306,[3,6,18,60...|\n",
      "|  0.0|(78306,[1,6,8,13,...|\n",
      "|  1.0|(78306,[11,13,14,...|\n",
      "|  2.0|(78306,[48,70,147...|\n",
      "|  3.0|(78306,[13,14,23,...|\n",
      "|  0.0|(78306,[8,10,23,5...|\n",
      "|  0.0|(78306,[4,8,24,38...|\n",
      "|  4.0|(78306,[1,4,9,11,...|\n",
      "|  1.0|(78306,[4,21,44,7...|\n",
      "|  3.0|(78306,[10,37,54,...|\n",
      "|  1.0|(78306,[4,8,24,33...|\n",
      "|  4.0|(78306,[1,7,11,36...|\n",
      "|  1.0|(78306,[1,4,7,34,...|\n",
      "|  2.0|(78306,[5,47,48,6...|\n",
      "|  0.0|(78306,[8,12,23,2...|\n",
      "|  1.0|(78306,[6,28,33,9...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clean_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "(training,testing)=clean_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictNB = NB.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "PredictRF= RF.fit(training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_results = PredictNB.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_results = PredictRF.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTC_results = PredictDTC.transform(testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(78306,[0,1,2,7,4...|[-1272.3084168820...|[4.69853735104021...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,7,1...|[-1201.6027268959...|[5.55082526493622...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,12,...|[-1147.6665627889...|[0.99999824007625...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,15,...|[-1686.3468091500...|[0.99999929069284...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[-1389.9759104929...|[5.82135401080913...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,17,...|[-2266.4304863658...|[8.97525001185602...|       3.0|\n",
      "|  0.0|(78306,[0,1,2,28,...|[-2044.3965287278...|[0.99999999999996...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,29,...|[-1851.1216944312...|[2.72418512189509...|       4.0|\n",
      "|  0.0|(78306,[0,1,2,46,...|[-527.36864716010...|[9.26276069333105...|       1.0|\n",
      "|  0.0|(78306,[0,1,2,54,...|[-1325.4137161224...|[3.39641162022602...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,4,6...|[-1170.5776206470...|[4.17812152367766...|       4.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-634.03687225059...|[0.09598701550775...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[-1429.2608636884...|[0.01335857420956...|       3.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[-1943.0543206016...|[0.98196626413937...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,7,1...|[-1695.9543344277...|[0.99957402781845...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,12,...|[-1480.5411902935...|[0.99999999917818...|       0.0|\n",
      "|  0.0|(78306,[0,1,4,16,...|[-1540.0508178265...|[0.99999999991847...|       0.0|\n",
      "|  0.0|(78306,[0,1,4,17,...|[-1005.4562475394...|[6.96542827002142...|       1.0|\n",
      "|  0.0|(78306,[0,1,5,7,1...|[-1378.1532721572...|[8.42624675124715...|       1.0|\n",
      "|  0.0|(78306,[0,1,5,7,4...|[-1620.5379846585...|[0.58486478778544...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NB_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|label|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "|  0.0|(78306,[0,1,2,7,4...|[13.6613630145247...|[0.27322726029049...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,7,1...|[13.6638310330250...|[0.27327662066050...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,12,...|[14.0945301423600...|[0.28189060284720...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,15,...|[13.5695430379821...|[0.27139086075964...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,16,...|[13.0924331553794...|[0.26184866310758...|       1.0|\n",
      "|  0.0|(78306,[0,1,2,17,...|[13.9214693829901...|[0.27842938765980...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,28,...|[14.1323023805481...|[0.28264604761096...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,29,...|[13.5130642983568...|[0.27026128596713...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,46,...|[13.6966723474252...|[0.27393344694850...|       0.0|\n",
      "|  0.0|(78306,[0,1,2,54,...|[13.5641418481352...|[0.27128283696270...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,4,6...|[13.8723635630716...|[0.27744727126143...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[13.8444894776978...|[0.27688978955395...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,1...|[13.8940634110088...|[0.27788126822017...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,6,5...|[13.8952592022823...|[0.27790518404564...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,7,1...|[13.8821977736667...|[0.27764395547333...|       0.0|\n",
      "|  0.0|(78306,[0,1,3,12,...|[13.9844666011085...|[0.27968933202217...|       0.0|\n",
      "|  0.0|(78306,[0,1,4,16,...|[13.6556197798059...|[0.27311239559611...|       0.0|\n",
      "|  0.0|(78306,[0,1,4,17,...|[13.9137593755474...|[0.27827518751094...|       0.0|\n",
      "|  0.0|(78306,[0,1,5,7,1...|[13.6249053954657...|[0.27249810790931...|       0.0|\n",
      "|  0.0|(78306,[0,1,5,7,4...|[13.7245711962728...|[0.27449142392545...|       0.0|\n",
      "+-----+--------------------+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RF_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DTC_results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = MulticlassClassificationEvaluator()\n",
    "acc_NB = eva.evaluate(NB_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "eva = MulticlassClassificationEvaluator()\n",
    "acc_RF = eva.evaluate(RF_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy of the NB and RF is :: 0.40332136698366144 0.12606511583689714\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy of the NB and RF is ::\", acc_NB, acc_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
